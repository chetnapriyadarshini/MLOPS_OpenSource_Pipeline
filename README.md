# 🚀 Lead Scoring System for CodePro

This system is designed to automatically **score leads based on their likelihood of purchasing CodePro’s course**, enabling the sales team to focus on high-quality leads and improve conversion efficiency.

---

## 🔧 System Overview

The project is structured into three modular pipelines — **Data Preprocessing**, **Model Training**, and **Inference** — all containerized with **Docker** and orchestrated using **Apache Airflow**.

---

## 📦 Project Structure

```bash
.
├── airflow/                        # Airflow DAGs, logs, and configs
├── db/                             # SQLite databases for training and inference
├── models/                         # Trained model artifacts
├── predictions/                    # CSVs generated by inference
├── lead_scoring_data_pipeline/     # Data preprocessing pipeline
├── lead_scoring_training_pipeline/ # Training pipeline
├── lead_scoring_inference_pipeline/# Inference pipeline
├── fastapi_app/                    # FastAPI app to serve predictions
├── docker-compose.yml              # Docker orchestration
└── README.md                       # Project documentation

# ⚙️ Pipelines

## 📊 1. Data Preprocessing Pipeline
- Cleans and prepares raw lead data.
- Maps city tiers, handles missing values, and maps categorical variables.
- Stores the cleaned data in a SQLite DB for training and inference.

## 🎯 2. Training Pipeline
- Trains a LightGBM classifier on the preprocessed data.
- Logs metrics and model using MLflow.
- Saves the model to the `models/` directory for use in inference.

## 🔮 3. Inference Pipeline
- Processes new lead data using the same transformations as training.
- Loads the trained model and generates conversion predictions.
- Saves predictions to `predictions/` and POSTs results to a FastAPI endpoint.

---

# 🌐 FastAPI Interface

The `fastapi_app` exposes routes to view and manage predictions:

### Endpoints
- `POST /show-prediction-from-csv`: Upload predictions from the pipeline.
- `GET /show-prediction-table`: View predictions as an HTML table in the browser.

> Example: Visit `http://127.0.0.1:8000/show-prediction-table` in your browser to view latest predictions.

---

# 🚀 Running the Project

### Step 1: Clone the Repository
```bash
git clone https://github.com/your-repo/lead-scoring-system.git
cd lead-scoring-system
```

### Step 2: Start All Services
```bash
docker-compose up --build
```

### Step 3: Access Services
- **Airflow Web UI**: http://localhost:8080
- **FastAPI UI**: http://localhost:8000
- **MLflow Tracking UI**: http://localhost:5050

> Make sure to trigger Airflow DAGs for data, training, and inference.

---

# 📦 Tech Stack

- **Apache Airflow** – Pipeline orchestration
- **Docker** – Containerized environment
- **FastAPI** – Lightweight API server
- **MLflow** – Model tracking and versioning
- **LightGBM** – High-performance model
- **SQLite** – Lightweight DB for processed data

---

# 🧪 Example Flow

1. Upload raw lead data to `/input/`.
2. Run the `data_pipeline` container or DAG to process data.
3. Run the `training` pipeline to build and log the model.
4. Run the `inference` pipeline to generate predictions.
5. View predictions via FastAPI browser endpoint.

---

# 📩 Contact

For questions, issues, or collaboration, please contact **[Chetna Priyadarshini]** at **[chetna.priya@gmail.com]**.

