# ðŸš€ Lead Scoring System for CodePro

This system is designed to automatically **score leads based on their likelihood of purchasing CodeProâ€™s course**, enabling the sales team to focus on high-quality leads and improve conversion efficiency.

---

## ðŸ”§ System Overview

The project is structured into three modular pipelines â€” **Data Preprocessing**, **Model Training**, and **Inference** â€” all containerized with **Docker** and orchestrated using **Apache Airflow**.

---

## ðŸ“¦ Project Structure

```bash
.
â”œâ”€â”€ airflow/                        # Airflow DAGs, logs, and configs
â”œâ”€â”€ db/                             # SQLite databases for training and inference
â”œâ”€â”€ models/                         # Trained model artifacts
â”œâ”€â”€ predictions/                    # CSVs generated by inference
â”œâ”€â”€ lead_scoring_data_pipeline/     # Data preprocessing pipeline
â”œâ”€â”€ lead_scoring_training_pipeline/ # Training pipeline
â”œâ”€â”€ lead_scoring_inference_pipeline/# Inference pipeline
â”œâ”€â”€ fastapi_app/                    # FastAPI app to serve predictions
â”œâ”€â”€ docker-compose.yml              # Docker orchestration
â””â”€â”€ README.md                       # Project documentation

# âš™ï¸ Pipelines

## ðŸ“Š 1. Data Preprocessing Pipeline
- Cleans and prepares raw lead data.
- Maps city tiers, handles missing values, and maps categorical variables.
- Stores the cleaned data in a SQLite DB for training and inference.

## ðŸŽ¯ 2. Training Pipeline
- Trains a LightGBM classifier on the preprocessed data.
- Logs metrics and model using MLflow.
- Saves the model to the `models/` directory for use in inference.

## ðŸ”® 3. Inference Pipeline
- Processes new lead data using the same transformations as training.
- Loads the trained model and generates conversion predictions.
- Saves predictions to `predictions/` and POSTs results to a FastAPI endpoint.

---

# ðŸŒ FastAPI Interface

The `fastapi_app` exposes routes to view and manage predictions:

### Endpoints
- `POST /show-prediction-from-csv`: Upload predictions from the pipeline.
- `GET /show-prediction-table`: View predictions as an HTML table in the browser.

> Example: Visit `http://127.0.0.1:8000/show-prediction-table` in your browser to view latest predictions.

---

# ðŸš€ Running the Project

### Step 1: Clone the Repository
```bash
git clone https://github.com/your-repo/lead-scoring-system.git
cd lead-scoring-system
```

### Step 2: Start All Services
```bash
docker-compose up --build
```

### Step 3: Access Services
- **Airflow Web UI**: http://localhost:8080
- **FastAPI UI**: http://localhost:8000
- **MLflow Tracking UI**: http://localhost:5050

> Make sure to trigger Airflow DAGs for data, training, and inference.

---

# ðŸ“¦ Tech Stack

- **Apache Airflow** â€“ Pipeline orchestration
- **Docker** â€“ Containerized environment
- **FastAPI** â€“ Lightweight API server
- **MLflow** â€“ Model tracking and versioning
- **LightGBM** â€“ High-performance model
- **SQLite** â€“ Lightweight DB for processed data

---

# ðŸ§ª Example Flow

1. Upload raw lead data to `/input/`.
2. Run the `data_pipeline` container or DAG to process data.
3. Run the `training` pipeline to build and log the model.
4. Run the `inference` pipeline to generate predictions.
5. View predictions via FastAPI browser endpoint.

---

# ðŸ“© Contact

For questions, issues, or collaboration, please contact **[Chetna Priyadarshini]** at **[chetna.priya@gmail.com]**.

